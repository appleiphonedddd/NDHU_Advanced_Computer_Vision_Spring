{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3\n",
    "1. Input BGR images from webcam.\n",
    "2. Detect your face, mouth, and eyes. \n",
    "3. Input BGRA images from files \"mustache.png\" and \"hat.png\" (hint: cv2.imread(\"mustache.png\", cv2.IMREAD_UNCHANGED) to read 4 channels)\n",
    "4. Perform <b> Alpha Blending </b> to add mustache and hat on the right position and orientation of your face.\n",
    "5. The overlaid mustache and hat should be translated, rotated , and scaled according to the movement of your face. \n",
    "6. Show your output images.\n",
    "7. Any idea on how to detect face features better? Try it and compare the results. (hint: modules of <i>dlib</i> or <i>mediapipe</i>)\n",
    "8. (5pts bonus) Open/Close your mouth to toggle mustache on/off.\n",
    "9. (5pts bonus) Blink your eye to toggle hat on/off.\n",
    "10. Upload your Jupyter code file (*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_cameras(max_index):\n",
    "    available_cameras = []\n",
    "    for i in range(max_index):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        \n",
    "        if cap.isOpened():\n",
    "            available_cameras.append(i)\n",
    "            cap.release()               \n",
    "    return available_cameras\n",
    "\n",
    "max_camera_index = 10\n",
    "available_cameras = list_available_cameras(max_camera_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Cameras: [0, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Available Cameras:\", available_cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_overlay(overlay_img, target_width):\n",
    "    h, w = overlay_img.shape[:2]\n",
    "    scaling_factor = target_width / float(w)\n",
    "    return cv2.resize(overlay_img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_image_alpha(img, img_overlay, pos, alpha_mask):\n",
    "    x, y = pos\n",
    "    y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n",
    "    x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n",
    "\n",
    "    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n",
    "    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n",
    "\n",
    "    if y1 >= y2 or x1 >= x2 or y1o >= y2o or x1o >= x2o:\n",
    "        return\n",
    "\n",
    "    for c in range(img.shape[2]):\n",
    "        img[y1:y2, x1:x2, c] = (alpha_mask[y1o:y2o, x1o:x2o] * img_overlay[y1o:y2o, x1o:x2o, c] +\n",
    "                                (1.0 - alpha_mask[y1o:y2o, x1o:x2o]) * img[y1:y2, x1:x2, c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "\n",
    "mustache_img = cv2.imread(\"mustache.png\", cv2.IMREAD_UNCHANGED)\n",
    "hat_img = cv2.imread(\"hat.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        continue\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(frame_rgb)\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "\n",
    "            mustache_width = int(w * 0.6)\n",
    "            resized_mustache_img = resize_overlay(mustache_img, mustache_width)\n",
    "            resized_mustache_alpha = resized_mustache_img[:, :, 3] / 255.0\n",
    "            resized_mustache_img = resized_mustache_img[:, :, :3]\n",
    "\n",
    "            hat_width = int(w * 1.0)\n",
    "            resized_hat_img = resize_overlay(hat_img, hat_width)\n",
    "            resized_hat_alpha = resized_hat_img[:, :, 3] / 255.0\n",
    "            resized_hat_img = resized_hat_img[:, :, :3]\n",
    "\n",
    "            mustache_pos = (x + int(w * 0.2), y + int(h * 0.5))\n",
    "            hat_pos = (x - int(w * 0.25), y - int(h * 0.25))\n",
    "\n",
    "            overlay_image_alpha(frame, resized_mustache_img, mustache_pos, resized_mustache_alpha)\n",
    "            overlay_image_alpha(frame, resized_hat_img, hat_pos, resized_hat_alpha)\n",
    "\n",
    "    cv2.imshow('Result', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
