{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "1. Input image from eos_map_x.png.\n",
    "2. Try to detect the location of the <b>player</b> (in cyan color), and the location of the nearest <b>shrine</b> (in red color). (hint: use <i>inRange()</i>)\n",
    "3. Try to detect the facing direction of the <b>player</b>. (hint: possibly use <i>morphologyEx()</i>, or <i>findContours(), minEnclosingTriangle()</i> to determine the player axis)\n",
    "4. Draw a yellow line indicating the facing direction of the <b>player</b>.\n",
    "5. Draw a yellow line from the <b>player</b> to the <b>shrine</b>.\n",
    "4. Compute the required <b>rotating angle</b> so the player is facing to the shrine. \n",
    "(positive angle means clockwise rotation, negative angle means counterclockwise rotaion) (hint: use <i>atan2()</i>)\n",
    "5. Print the rotating angle on top-left corner of the output images. (in degree, not radian)\n",
    "6. Write a simple report in a separate cell.\n",
    "7. Upload your Jupyter code file (*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_max_area(contours):\n",
    "    areas = [cv2.contourArea(contour) for contour in contours]\n",
    "    if areas:\n",
    "        return max(areas)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def find_centers_and_areas(contours, min_area_threshold):\n",
    "    centers = []\n",
    "    areas = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        areas.append(area)\n",
    "        if area > min_area_threshold:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                centers.append((cX, cY))\n",
    "    return centers, areas\n",
    "\n",
    "def find_closest_points(centers1, centers2):\n",
    "    min_dist = float('inf')\n",
    "    closest_point1 = None\n",
    "    closest_point2 = None\n",
    "    for center1 in centers1:\n",
    "        for center2 in centers2:\n",
    "            dist = np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_point1 = center1\n",
    "                closest_point2 = center2\n",
    "    return closest_point1, closest_point2\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('eos_map_0.png')\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 定义颜色区域的HSV范围\n",
    "red_low = np.array([0, 100, 100])  \n",
    "red_up  = np.array([0, 255, 255])    \n",
    "blue_low = np.array([90, 100, 100])\n",
    "blue_up  = np.array([120, 255, 255])  \n",
    "\n",
    "# 创建红色和蓝色的遮罩\n",
    "red_mask  = cv2.inRange(img_hsv, red_low,  red_up)\n",
    "blue_mask = cv2.inRange(img_hsv, blue_low, blue_up)\n",
    "\n",
    "# 对遮罩进行形态学操作\n",
    "kernel_dot = np.ones((3,3), np.uint8)\n",
    "red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel_dot)\n",
    "blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel_dot)\n",
    "\n",
    "# 找到红色区域的中心点及面积\n",
    "red_contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "red_centers, red_areas = find_centers_and_areas(red_contours, 110)\n",
    "max_red_area = find_max_area(red_contours)\n",
    "\n",
    "# 找到蓝色区域的中心点及面积\n",
    "blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "blue_centers, blue_areas = find_centers_and_areas(blue_contours, 40)\n",
    "max_blue_area = find_max_area(blue_contours)\n",
    "\n",
    "# 找到最接近的红色和蓝色中心点\n",
    "if red_centers and blue_centers:\n",
    "    closest_red, closest_blue = find_closest_points(red_centers, blue_centers)\n",
    "\n",
    "# 其余部分保持不变\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red_center: (117, 86)\n",
      "angle: -124.08588699418924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.033] global loadsave.cpp:248 findDecoder imread_('path_to_image'): can't open/read file: check file path/integrity\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/infor/miniconda3/envs/computervision/lib/python3.9/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# 近似藍色區域的輪廓\n",
    "epsilon = 0.1 * cv2.arcLength(blue_contours[0], True)\n",
    "approx = cv2.approxPolyDP(blue_contours[0], epsilon, True)\n",
    "\n",
    "# 找到凸包\n",
    "hull = cv2.convexHull(approx)\n",
    "\n",
    "# 提取凸包的頂點\n",
    "hull_points = [tuple(point[0]) for point in hull]\n",
    "\n",
    "\n",
    "#intersection = hull_points[2]\n",
    "\n",
    "# 計算兩條長邊的交點\n",
    "side_length_ab =  ((hull_points[0][0] - hull_points[1][0])** 2 + (hull_points[0][1] - hull_points[1][1])** 2 ) ** 0.5\n",
    "side_length_ac =  ((hull_points[0][0] - hull_points[2][0])** 2 + (hull_points[0][1] - hull_points[2][1])** 2 ) ** 0.5\n",
    "side_length_bc =  ((hull_points[1][0] - hull_points[2][0])** 2 + (hull_points[1][1] - hull_points[2][1])** 2 ) ** 0.5\n",
    "\n",
    "\n",
    "max_side_length = max(side_length_ab + side_length_ac , side_length_bc + side_length_ac, side_length_ab + side_length_bc)\n",
    "\n",
    "if max_side_length == side_length_ab + side_length_ac: #a\n",
    "    intersection = hull_points[0]\n",
    "    \n",
    "if max_side_length == side_length_ab + side_length_bc: #b\n",
    "    intersection = hull_points[1]\n",
    "    \n",
    "if max_side_length == side_length_ac + side_length_bc: #c\n",
    "    intersection = hull_points[2]\n",
    "\n",
    "\n",
    "\n",
    "vector = np.array(closest_red) - np.array(intersection)\n",
    "\n",
    "extended_vector = 2 * vector\n",
    "\n",
    "cv2.line(image, closest_red, intersection, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "cv2.line(image, intersection, tuple(extended_vector), (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "cv2.circle(image, intersection, 5, (255, 0, 0), -1)\n",
    "img_with_yellow_lines = cv2.imread('path_to_image')\n",
    "print('red_center:', closest_red)\n",
    "\n",
    "\n",
    "blue_center = closest_blue\n",
    "red_center = closest_red\n",
    "intersection = intersection\n",
    "\n",
    "\n",
    "vector_blue = np.array(blue_center) - np.array(intersection)\n",
    "vector_red = np.array(red_center) - np.array(intersection)\n",
    "\n",
    "\n",
    "cosine_angle = np.dot(vector_blue, vector_red) / (np.linalg.norm(vector_blue) * np.linalg.norm(vector_red))\n",
    "angle = np.arccos(cosine_angle)\n",
    "angle = np.degrees(angle)\n",
    "\n",
    "\n",
    "\n",
    "if vector_blue[1] < 0:\n",
    "    angle = -angle\n",
    "if vector_red[1] < 0:\n",
    "    angle = -angle\n",
    "\n",
    "\n",
    "\n",
    "print('angle:', angle)\n",
    "\n",
    "\n",
    "\n",
    "cv2.putText(image, f'angle: {angle:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
