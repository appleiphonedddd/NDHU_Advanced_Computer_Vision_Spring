{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### %%writefile test\n",
    "## Midterm\n",
    "<b>The objective of the first part of the midterm is to detect blue cursor, yellow timer, and human skin from input video. Your output should be similar to midterm_demo.mp4. Please complete steps 1-8 in one single code cell. The whole process can be divided to the following steps:</b>\n",
    "1. (5pts) Input images from video file WiiPlay.mp4 with the same level number as the last two digits of your student id, and show the images in the \"input\" window.\n",
    "2. (5pts) Use <i>cv2.cvtColor()</i> to convert images from BGR to HSV format.\n",
    "3. (5pts) Use <i>cv2.createTrackbar()</i> to create six trackbars (HueMin, HueMax, SatMin SatMax, ValMin, ValMax), and use <i>cv2.getTrackbarPos()</i> to get the current value of each trackbar.\n",
    "4. (5pts) Use <i>cv2.threshold()</i> or <i>cv2.inRange()</i> to apply double thresholding to each channel (Hue, Sat, Val) based on current values of the six trackbars\n",
    "5. (5pts) Apply morphological filters to remove noise (outliers & holes), and show the detected regions in the \"test\" window..\n",
    "6. (10pts) Find out the best color range to detect <b>blue cursor</b>, apply these thresholds, and show the detected regions in the \"cursor\" window.\n",
    "7. (10pts) Find out the best color range to detect <b>yellow timer</b>, apply these thresholds, and show the detected regions in the \"timer\" window.\n",
    "8. (10pts) Find out the best color range to detect <b>human skin</b>, apply these thresholds, and show the detected regions in the \"skin\" window.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(\"WiiPlay.mp4\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open the video file\")\n",
    "\n",
    "frame_start = 150\n",
    "frame_end = 437\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_start)\n",
    "cv2.namedWindow('input')\n",
    "cv2.namedWindow('test')\n",
    "cv2.namedWindow('cursor')\n",
    "cv2.namedWindow('timer')\n",
    "cv2.namedWindow('skin')\n",
    "\n",
    "# 3. Use cv2.createTrackbar() to create six trackbars\n",
    "cv2.createTrackbar('HueMin', 'test', 0, 30, nothing)\n",
    "cv2.createTrackbar('HueMax', 'test', 0, 150, nothing)\n",
    "cv2.createTrackbar('SatMin', 'test', 0, 10, nothing)\n",
    "cv2.createTrackbar('SatMax', 'test', 0, 120, nothing)\n",
    "cv2.createTrackbar('ValMin', 'test', 0, 50, nothing)\n",
    "cv2.createTrackbar('ValMax', 'test', 0, 200, nothing)\n",
    "\n",
    "cv2.createTrackbar('BlueHueMin', 'cursor', 100, 180, nothing)\n",
    "cv2.createTrackbar('BlueHueMax', 'cursor', 120, 180, nothing)\n",
    "cv2.createTrackbar('BlueSatMin', 'cursor', 100, 255, nothing)\n",
    "cv2.createTrackbar('BlueSatMax', 'cursor', 255, 255, nothing)\n",
    "cv2.createTrackbar('BlueValMin', 'cursor', 100, 255, nothing)\n",
    "cv2.createTrackbar('BlueValMax', 'cursor', 255, 255, nothing)\n",
    "\n",
    "cv2.createTrackbar('YellowHueMin', 'timer', 20, 30, nothing)\n",
    "cv2.createTrackbar('YellowHueMax', 'timer', 30, 30, nothing)\n",
    "cv2.createTrackbar('YellowSatMin', 'timer', 100, 255, nothing)\n",
    "cv2.createTrackbar('YellowSatMax', 'timer', 255, 255, nothing)\n",
    "cv2.createTrackbar('YellowValMin', 'timer', 100, 255, nothing)\n",
    "cv2.createTrackbar('YellowValMax', 'timer', 255, 255, nothing)\n",
    "\n",
    "cv2.createTrackbar('SkinHueMin', 'skin', 0, 30, nothing)\n",
    "cv2.createTrackbar('SkinHueMax', 'skin', 20, 30, nothing)\n",
    "cv2.createTrackbar('SkinSatMin', 'skin', 40, 255, nothing)\n",
    "cv2.createTrackbar('SkinSatMax', 'skin', 255, 255, nothing)\n",
    "cv2.createTrackbar('SkinValMin', 'skin', 50, 255, nothing)\n",
    "cv2.createTrackbar('SkinValMax', 'skin', 255, 255, nothing)\n",
    "\n",
    "current_frame = frame_start\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Reached end of video\")\n",
    "        break\n",
    "    \n",
    "    \"\"\" \n",
    "    1.Input images from video file WiiPlay.mp4 \n",
    "    with the same level number as the last two digits of your student id, \n",
    "    and show the images in the \"input\" window\n",
    "    \"\"\"\n",
    "    cv2.imshow('input', frame)\n",
    "\n",
    "    # 2. Use cv2.cvtColor() to convert images from BGR to HSV format.\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 3. use cv2.getTrackbarPos() to get the current value of each trackbar.\n",
    "    hmin = cv2.getTrackbarPos('HueMin', 'test')\n",
    "    hmax = cv2.getTrackbarPos('HueMax', 'test')\n",
    "    smin = cv2.getTrackbarPos('SatMin', 'test')\n",
    "    smax = cv2.getTrackbarPos('SatMax', 'test')\n",
    "    vmin = cv2.getTrackbarPos('ValMin', 'test')\n",
    "    vmax = cv2.getTrackbarPos('ValMax', 'test')\n",
    "\n",
    "    blue_h_min = cv2.getTrackbarPos('BlueHueMin', 'cursor')\n",
    "    blue_h_max = cv2.getTrackbarPos('BlueHueMax', 'cursor')\n",
    "    blue_s_min = cv2.getTrackbarPos('BlueSatMin', 'cursor')\n",
    "    blue_s_max = cv2.getTrackbarPos('BlueSatMax', 'cursor')\n",
    "    blue_v_min = cv2.getTrackbarPos('BlueValMin', 'cursor')\n",
    "    blue_v_max = cv2.getTrackbarPos('BlueValMax', 'cursor')\n",
    "\n",
    "    # Get current trackbar positions for yellow timer detection\n",
    "    yellow_h_min = cv2.getTrackbarPos('YellowHueMin', 'timer')\n",
    "    yellow_h_max = cv2.getTrackbarPos('YellowHueMax', 'timer')\n",
    "    yellow_s_min = cv2.getTrackbarPos('YellowSatMin', 'timer')\n",
    "    yellow_s_max = cv2.getTrackbarPos('YellowSatMax', 'timer')\n",
    "    yellow_v_min = cv2.getTrackbarPos('YellowValMin', 'timer')\n",
    "    yellow_v_max = cv2.getTrackbarPos('YellowValMax', 'timer')\n",
    "\n",
    "    skin_h_min = cv2.getTrackbarPos('SkinHueMin', 'skin')\n",
    "    skin_h_max = cv2.getTrackbarPos('SkinHueMax', 'skin')\n",
    "    skin_s_min = cv2.getTrackbarPos('SkinSatMin', 'skin')\n",
    "    skin_s_max = cv2.getTrackbarPos('SkinSatMax', 'skin')\n",
    "    skin_v_min = cv2.getTrackbarPos('SkinValMin', 'skin')\n",
    "    skin_v_max = cv2.getTrackbarPos('SkinValMax', 'skin')\n",
    "\n",
    "\n",
    "    lower = np.array([hmin, smin, vmin])\n",
    "    upper = np.array([hmax, smax, vmax])\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    lower_yellow = np.array([yellow_h_min, yellow_s_min, yellow_v_min])\n",
    "    upper_yellow = np.array([yellow_h_max, yellow_s_max, yellow_v_max])\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Define lower and upper bounds for blue cursor detection\n",
    "    lower_blue = np.array([blue_h_min, blue_s_min, blue_v_min])\n",
    "    upper_blue = np.array([blue_h_max, blue_s_max, blue_v_max])\n",
    "\n",
    "    # Threshold the HSV image to get only blue cursor\n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Define lower and upper bounds for skin detection\n",
    "    lower_skin = np.array([skin_h_min, skin_s_min, skin_v_min])\n",
    "    upper_skin = np.array([skin_h_max, skin_s_max, skin_v_max])\n",
    "\n",
    "    # Threshold the HSV image to get only skin\n",
    "    mask_skin = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_blue = cv2.erode(mask_blue, kernel, iterations=1)\n",
    "    mask_blue = cv2.dilate(mask_blue, kernel, iterations=1)\n",
    "\n",
    "    mask_yellow = cv2.erode(mask_yellow, kernel, iterations=1)\n",
    "    mask_yellow = cv2.dilate(mask_yellow, kernel, iterations=1)\n",
    "\n",
    "    mask_skin = cv2.erode(mask_skin, kernel, iterations=1)\n",
    "    mask_skin = cv2.dilate(mask_skin, kernel, iterations=1)\n",
    "\n",
    "    cv2.imshow('input', frame)\n",
    "    cv2.imshow('test', mask)\n",
    "    cv2.imshow('cursor', mask_blue)\n",
    "    cv2.imshow('timer', mask_yellow)\n",
    "    cv2.imshow('skin', mask_skin)\n",
    "    current_frame += 1\n",
    "\n",
    "    if current_frame > frame_end:\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The objective of the second part of the midterm is to stitch images together. Your output should be similar to the following picture. The coordinates of four pairs of corresponding points between two consecutive images should be provided <b style=\"color:red;\">manually</b> (don't match automatically). Please complete steps 9-12 in one single code cell, steps 13-14 in another markdown cell, and upload your Jupyter notebook file (*.ipynb).</b>\n",
    "\n",
    "9. (5pts) Given a pair of images (pier_1.jpg, pier_2.jpg), use <i>cv2.getPerspectiveTransform()</i> to get Homography Matrix by specifing the coordinates of four pairs of corresponding points <b>manually</b>.\n",
    "10. (10pts) Use <i>cv2.warpPerspective()</i> and the Homography Matrix to get the projective view of the second image. You might need to make the output image larger enough to fit the projective image.\n",
    "11. (10pts) Use <i>cv2.add()</i> to stitch two images together.\n",
    "12. (10pts) Given a set of three images (pier_1.jpg, pier_2.jpg, pier_3.jpg) and their corresponding points, try to stitch them together.\n",
    "13. (5pts) Any comments regarding the midterm? Which steps you believe you have completed? Which steps bother you?\n",
    "14. (5pts) Any comments regarding the classes up to now? pace too fast or slow? quiz too hard or simple? prefer C or Python?\n",
    " ![pier_homography_output.jpg](attachment:pier_homography_output.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"pier_1.jpg\")\n",
    "img2 = cv2.imread(\"pier_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cv2.PerspectiveTransform() to get Homography matrix\n",
    "img1_p1 = np.float32([[100, 100], [480, 0], [0, 360], [480, 360]])\n",
    "img1_p2 = np.float32([[100, 100], [480, 0], [0, 360], [480, 360]])\n",
    "\n",
    "H = cv2.getPerspectiveTransform(img1_p1, img1_p2)\n",
    "\n",
    "# use cv2.warpPerspective() to get the transformed image\n",
    "img1_p = cv2.warpPerspective(img1, H, (480, 360))\n",
    "\n",
    "cv2.imshow('img1', img1)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
