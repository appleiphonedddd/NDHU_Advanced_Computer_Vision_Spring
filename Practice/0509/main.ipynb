{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "1. Input images from webcam.\n",
    "2. Use <b>MediaPipe()</b> to peform face detection.\n",
    "3. Find the coordinates of 6 FaceKeyPoint: (RIGHT_EYE,LEFT_EYE,NOSE_TIP,MOUTH_CENTER,RIGHT_EAR_TRAGION,LEFT_EAR_TRAGION)\n",
    "4. Draw a triangle using three points: RIGHT_EYE, LEFT_EYE, MOUTH_CENTER\n",
    "5. Use <i>cv2.arrowedLine()</i> to indicate the normal direction of the face. (hint: a vector from the center of the triangle to the NOSE_TIP)\n",
    "6. Show the output image.\n",
    "7. Upload your Jupyter code file (*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.889] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ERROR:0@1.006] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Cameras: [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.093] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video3): can't open camera by index\n",
      "[ERROR:0@1.094] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1.095] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video4): can't open camera by index\n",
      "[ERROR:0@1.096] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1.096] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video5): can't open camera by index\n",
      "[ERROR:0@1.097] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1.097] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video6): can't open camera by index\n",
      "[ERROR:0@1.098] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1.098] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video7): can't open camera by index\n",
      "[ERROR:0@1.099] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1.099] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video8): can't open camera by index\n",
      "[ERROR:0@1.100] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1.100] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video9): can't open camera by index\n",
      "[ERROR:0@1.101] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "def list_available_cameras(max_index):\n",
    "    available_cameras = []\n",
    "    for i in range(max_index):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        \n",
    "        if cap.isOpened():\n",
    "            available_cameras.append(i)\n",
    "            cap.release()               \n",
    "    return available_cameras\n",
    "\n",
    "max_camera_index = 10\n",
    "available_cameras = list_available_cameras(max_camera_index)\n",
    "\n",
    "print(\"Available Cameras:\", available_cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "face_detection = mp_face_detection.FaceDetection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "/home/infor/miniconda3/envs/computervision/lib/python3.9/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image.flags.writeable = False\n",
    "    results = face_detection.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(image, detection)\n",
    "            \n",
    "            \n",
    "            for id, landmark in enumerate(detection.location_data.relative_keypoints):\n",
    "                h, w, c = image.shape\n",
    "                \n",
    "                if id in [0, 1, 2, 3, 4, 5]: \n",
    "                    cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "                    \n",
    "                    cv2.circle(image, (cx, cy), 2, (255, 0, 255), cv2.FILLED)\n",
    "                \n",
    "                if id == 0:  # RIGHT_EYE\n",
    "                    right_eye = (cx, cy)\n",
    "                elif id == 1:  # LEFT_EYE\n",
    "                    left_eye = (cx, cy)\n",
    "                elif id == 2:  # NOSE_TIP\n",
    "                    nose_tip = (cx, cy)\n",
    "                elif id == 3:  # MOUTH_CENTER\n",
    "                    mouth_center = (cx, cy)\n",
    "            \n",
    "            triangle_cnt = [right_eye, left_eye, mouth_center]\n",
    "            cv2.drawContours(image, [np.array(triangle_cnt)], 0, (0, 255, 0), -1)\n",
    "            \n",
    "            centroid_x = int((right_eye[0] + left_eye[0] + mouth_center[0]) / 3)\n",
    "            centroid_y = int((right_eye[1] + left_eye[1] + mouth_center[1]) / 3)\n",
    "            centroid = (centroid_x, centroid_y)\n",
    "            \n",
    "            cv2.arrowedLine(image, centroid, nose_tip, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('MediaPipe Face Detection', image)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result](final.png \"Result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
