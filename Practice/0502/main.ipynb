{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "1. Input images from video file WiiPlay.mp4 with frame number between 4820 and 5000 (i.e., level 15).\n",
    "2. Acquire a face template from the first frame (frame number = 4820).\n",
    "3. Use <i>cv2.matchTemplate()</i> to perform template matching on subsequent frames.\n",
    "4. Draw a blue rectangle around each good match and show the output images.\n",
    "5. (Optional) Use <i>cv2.minMaxLoc()</i> to find the best match and draw a red rectangle around the best match.\n",
    "6. Observe which method is better ('cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR','cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED') \n",
    "7. Upload your Jupyter code file (*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/infor/miniconda3/envs/computervision/lib/python3.9/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"WiiPlay.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video stream or file\")\n",
    "    exit()\n",
    "\n",
    "frame_start = 4820\n",
    "frame_end = 5000\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_start)\n",
    "\n",
    "ret, template = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Failed to read the first frame.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "template_roi = template[100:200, 300:600] \n",
    "\n",
    "# Setup for template matching\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "current_frame = frame_start + 1\n",
    "\n",
    "while current_frame <= frame_end:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Reached end of video\")\n",
    "        break\n",
    "\n",
    "    for method in methods:\n",
    "        result = cv2.matchTemplate(frame, template_roi, eval(method))\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        if method in ['cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "\n",
    "        bottom_right = (top_left[0] + template_roi.shape[1], top_left[1] + template_roi.shape[0])\n",
    "        cv2.rectangle(frame, top_left, bottom_right, (255, 0, 0), 2)  # Blue rectangle for good matches\n",
    "\n",
    "        cv2.rectangle(frame, top_left, bottom_right, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    current_frame += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result](result.png \"Result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
