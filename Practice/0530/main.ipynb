{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice : Detector followed by Tracker\n",
    "\n",
    "1. Input images from wiiplay.mp4 for level 52 (frame number:19400~20000).\n",
    "2. Use <i>cv2.HOGDescriptor()</i> to <b>detect</b> pedestrian on the first frame. (frame number=19400)\n",
    "3. Try to <b>track</b> the detected pedestrian on subsequent frames. (marked as <b>red</b> rectangle)\n",
    "4. Insted of detection followed by tracking, try to detect pedestrian on each frames without tracking. (marked as <b>green</b> rectangle)\n",
    "5. Observe the results and compare the difference between these two approaches. \n",
    "6. Show your output images.\n",
    "7. Upload your Jupyter code file (*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Capture and Pedestrian Detection in OpenCV\n",
    "\n",
    "The process below outlines the steps for capturing video frames and applying pedestrian detection using OpenCV's Histogram of Oriented Gradients (HOG) descriptor and Support Vector Machine (SVM) classifier.\n",
    "\n",
    "#### Reading the Video\n",
    "\n",
    "Open the video file `WiiPlay.mp4` for processing.\n",
    "\n",
    "$$\n",
    "\\text{cap} = \\text{cv2.VideoCapture}('WiiPlay.mp4')\n",
    "$$\n",
    "\n",
    "#### Defining Start and End Frames\n",
    "\n",
    "Specify the range of frames between which the processing will be performed.\n",
    "\n",
    "$$\n",
    "\\text{start\\_frame} = 19400 \\newline\n",
    "\\text{end\\_frame} = 20000\n",
    "$$\n",
    "\n",
    "#### Setting the Start Frame\n",
    "Set the video's starting point to the frame number 'start_frame'\n",
    "\n",
    "$$\n",
    "\\text{cap.set(cv2.CAP\\_PROP\\_POS\\_FRAMES, start\\_frame)}\n",
    "$$\n",
    "\n",
    "#### Initializing the HOG Descriptor\n",
    "The Histogram of Oriented Gradients (HOG) is used to detect objects. The Support Vector Machine (SVM) classifier is set with the default people detector.\n",
    "\n",
    "$$\n",
    "\\text{hog} = \\text{cv2.HOGDescriptor}() \\newline\n",
    "\\text{hog.setSVMDetector(cv2.HOGDescriptor\\_getDefaultPeopleDetector())}\n",
    "$$\n",
    "\n",
    "#### Processing Each Frame:\n",
    "\n",
    "The loop processes each frame one by one until the end frame is reached.\n",
    "$$\n",
    "\\text{while True:}\n",
    "$$\n",
    "\n",
    "#### Reading the Current Frame:\n",
    "\n",
    "$$\n",
    "\\text{ret}, \\text{img} = \\text{cap.read()}\n",
    "$$\n",
    "\n",
    "### Detecting Pedestrians\n",
    "\n",
    "#### Applying HOG Descriptor:\n",
    "The detectMultiScale method detects objects (pedestrians) in the current frame. It returns rectangles (rects) around detected objects and their corresponding weights.\n",
    "\n",
    "$$\n",
    "(\\text{rects}, \\text{weights}) = \\text{hog.detectMultiScale}(\\text{img}, \\text{winStride}=(4, 4), \\text{padding}=(8, 8), \\text{scale}=1.05)\n",
    "$$\n",
    "\n",
    "#### Mathematical Explanation of HOG + SVM:\n",
    "HOG extracts features from the image by computing the gradient orientations in localized parts of the image, while the SVM classifier is used to detect pedestrians based on those features\n",
    "\n",
    "$$\n",
    "\\text{HOG}(I) = \\sum_{x, y} \\text{Gradient}(I_{x,y}) \\newline\n",
    "\n",
    "\\text{SVM}(HOG(I)) = \n",
    "\\begin{cases}\n",
    "1 & \\text{if pedestrian} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/infor/miniconda3/envs/CV/lib/python3.9/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('WiiPlay.mp4')\n",
    "\n",
    "start_frame_number = 19400\n",
    "end_frame_number = 20000\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_number)\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the video\")\n",
    "    exit()\n",
    "\n",
    "boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "\n",
    "for (x, y, w, h) in boxes:\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "trackers = cv2.legacy.MultiTracker_create()\n",
    "for box in boxes:\n",
    "    tracker = cv2.legacy.TrackerMIL_create()\n",
    "    trackers.add(tracker, frame, tuple(box))\n",
    "\n",
    "frame_count = start_frame_number\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame_count >= end_frame_number:\n",
    "        break\n",
    "\n",
    "    success, tracked_boxes = trackers.update(frame)\n",
    "    if success:\n",
    "       \n",
    "        for box in tracked_boxes:\n",
    "            x, y, w, h = [int(v) for v in box]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    detected_boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "    for (x, y, w, h) in detected_boxes:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    text = f'Current_Frame: {frame_count}'\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "    text_x = frame.shape[1] - text_size[0] - 10\n",
    "    text_y = 30\n",
    "    cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Result', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
