{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice : Detector followed by Tracker\n",
    "\n",
    "1. Input images from wiiplay.mp4 for level 52 (frame number:19400~20000).\n",
    "2. Use <i>cv2.HOGDescriptor()</i> to <b>detect</b> pedestrian on the first frame. (frame number=19400)\n",
    "3. Try to <b>track</b> the detected pedestrian on subsequent frames. (marked as <b>red</b> rectangle)\n",
    "4. Insted of detection followed by tracking, try to detect pedestrian on each frames without tracking. (marked as <b>green</b> rectangle)\n",
    "5. Observe the results and compare the difference between these two approaches. \n",
    "6. Show your output images.\n",
    "7. Upload your Jupyter code file (*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Capture and Pedestrian Detection in OpenCV\n",
    "\n",
    "The process below outlines the steps for capturing video frames and applying pedestrian detection using OpenCV's Histogram of Oriented Gradients (HOG) descriptor and Support Vector Machine (SVM) classifier.\n",
    "\n",
    "#### Reading the Video\n",
    "\n",
    "Open the video file `WiiPlay.mp4` for processing.\n",
    "\n",
    "$$\n",
    "\\text{cap} = \\text{cv2.VideoCapture}('WiiPlay.mp4')\n",
    "$$\n",
    "\n",
    "#### Defining Start and End Frames\n",
    "\n",
    "Specify the range of frames between which the processing will be performed.\n",
    "\n",
    "$$\n",
    "\\text{start\\_frame} = 19400 \\newline\n",
    "\\text{end\\_frame} = 20000\n",
    "$$\n",
    "\n",
    "#### Setting the Start Frame\n",
    "Set the video's starting point to the frame number 'start_frame'\n",
    "\n",
    "$$\n",
    "\\text{cap.set(cv2.CAP\\_PROP\\_POS\\_FRAMES, start\\_frame)}\n",
    "$$\n",
    "\n",
    "#### Initializing the HOG Descriptor\n",
    "The Histogram of Oriented Gradients (HOG) is used to detect objects. The Support Vector Machine (SVM) classifier is set with the default people detector.\n",
    "\n",
    "$$\n",
    "\\text{hog} = \\text{cv2.HOGDescriptor}() \\newline\n",
    "\\text{hog.setSVMDetector(cv2.HOGDescriptor\\_getDefaultPeopleDetector())}\n",
    "$$\n",
    "\n",
    "#### Processing Each Frame:\n",
    "\n",
    "The loop processes each frame one by one until the end frame is reached.\n",
    "$$\n",
    "\\text{while True:}\n",
    "$$\n",
    "\n",
    "#### Reading the Current Frame:\n",
    "\n",
    "$$\n",
    "\\text{ret}, \\text{img} = \\text{cap.read()}\n",
    "$$\n",
    "\n",
    "### Detecting Pedestrians\n",
    "\n",
    "#### Applying HOG Descriptor:\n",
    "The detectMultiScale method detects objects (pedestrians) in the current frame. It returns rectangles (rects) around detected objects and their corresponding weights.\n",
    "\n",
    "$$\n",
    "(\\text{rects}, \\text{weights}) = \\text{hog.detectMultiScale}(\\text{img}, \\text{winStride}=(4, 4), \\text{padding}=(8, 8), \\text{scale}=1.05)\n",
    "$$\n",
    "\n",
    "#### Mathematical Explanation of HOG + SVM:\n",
    "HOG extracts features from the image by computing the gradient orientations in localized parts of the image, while the SVM classifier is used to detect pedestrians based on those features\n",
    "\n",
    "$$\n",
    "\\text{HOG}(I) = \\sum_{x, y} \\text{Gradient}(I_{x,y}) \\newline\n",
    "\n",
    "\\text{SVM}(HOG(I)) = \n",
    "\\begin{cases}\n",
    "1 & \\text{if pedestrian} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture('WiiPlay.mp4')\n",
    "\n",
    "# Define the start and end frame numbers\n",
    "start_frame = 19400\n",
    "end_frame = 20000\n",
    "\n",
    "# Set the current frame to the start frame\n",
    "current_frame_number = start_frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    # Break the loop if no frame is returned or the end frame is reached\n",
    "    if not ret or current_frame_number > end_frame:\n",
    "        break\n",
    "\n",
    "    # Detect pedestrians in the current frame\n",
    "    (rects, weights) = hog.detectMultiScale(img, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # Draw rectangles around detected pedestrians\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Prepare text showing the current frame number\n",
    "    text = f'Current_Frame: {current_frame_number}'\n",
    "\n",
    "    # Get the size of the text for positioning\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "\n",
    "    # Calculate text position: 10 pixels from the right edge, 30 pixels from the top edge\n",
    "    text_x = img.shape[1] - text_size[0] - 10\n",
    "    text_y = 30\n",
    "\n",
    "    # Draw the text on the frame\n",
    "    cv2.putText(img, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', img)\n",
    "\n",
    "    # Increment the frame counter\n",
    "    current_frame_number += 1\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
